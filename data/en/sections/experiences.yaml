# section information
section:
  name: Experiences
  id: experiences
  enable: true
  weight: 4
  showOnNavbar: true
  # Can optionally hide the title in sections
  # hideTitle: true 

# Your experiences
experiences:
- company:
    name: Spatial Sciences Institute, USC
    url: "https://spatial.usc.edu/"
    location: Los Angeles
    # company overview
  positions:
  - designation: Text Detection and Recognition for Historical Maps
    start: Dec 2019
    end: Aug 2020
    # don't provide end date if you are currently working there. It will be replaced by "Present"
    # end: Dec 2020
    # give some points about what was your responsibilities at the company.
    responsibilities:
    - Built a deep neural network for detecting text of various font size, style and orientation angles on historical map patches. The network is able to handle text regions of arbitrary shapes
    - Designed the network to highlight probable text regions and then predict accurate bounding boxes given both map features and text probability distributions in a coarse-to-fine manner

- company:
    name: Spatial Sciences Institute, USC
    url: "https://spatial.usc.edu/"
    location: Los Angeles
  positions:
  - designation: Generating Historical Maps from online Maps
    start: Aug 2018
    end: Dec 2019
    responsibilities:
    - Synthesized historical maps from Open Street Map tiles with conditional generative adversarial networks
    - The network generated background and foreground separately using different targets to solve the content mismatch problem in online maps and historical maps
    - Used the synthesized historical maps as the base-map and automatically place text labels on them to provide a large amount of training data for text detection networks

- company:
    name: Amazon
    url: "https://www.amazon.com/"
    location: Seattle (Remote)
  positions:
  - designation: Synthetic Face Generation for Facial Landmark Detection
    start: May 2020
    end: Aug 2020
    responsibilities:
    - Built a pipeline to generate synthetic face images with landmark annotations using 3D modeling application Makehuman and rendering application Blender
    - Rendered the images from 3D models with various poses, camera setting, lighting conditions and backgrounds
    - Verified that the 2D landmark detection task and the 3D mesh prediction task can both benefit from the large amount of generated synthetic images

- company:
    name: Microsoft Research Asia
    url: "https://www.microsoft.com/en-us/research/lab/microsoft-research-asia/"
    location: Beijing, China
  positions:
  - designation: Automated Visual Data Extraction from Chart Images
    start: May 2019
    end: Aug 2019
    responsibilities:
    - Built a pipeline to automatically infer numerical values for each chart given the column chart images
    - Applied trident-net to extract the chart object heights. Designed a ruler encoding module to interpret the y-axis information to convert the objects from pixel-space to ruler space to generate reading
    - The ruler encoding module focuses on the minimum and maximum values of the ruler to decide the numerical range that the charts represent
